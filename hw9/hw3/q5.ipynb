{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n",
      "   category   popular     genre\n",
      "0         1 -0.811510  0.748751\n",
      "1         2 -0.091522 -0.889338\n",
      "2         2  0.339104 -0.683431\n",
      "3         1 -0.254350  0.820988\n",
      "4         2 -0.531400 -1.983743\n",
      "(80000, 3)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"quality_test.csv\")\n",
    "train_df = pd.read_csv(\"quality_train.csv\")\n",
    "\n",
    "print(test_df.shape)\n",
    "print(test_df.head())\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category'] = train_df['category'] - 1\n",
    "#train_df['category'] = train_df['category'].astype('category')\n",
    "\n",
    "test_df['category'] = test_df['category'] - 1\n",
    "#test_df['category'] = test_df['category'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model equation is:\n",
    "\n",
    "logit(ð‘ƒ(Y=k)) = $ð›½_{0,k}$ + $ð›½_{1,k}$ * popular + $ð›½_{2,k}$ * genre \n",
    "\n",
    "where Y is the response variable (category), ð‘ƒ(Y=k) is the probability of category k, and  $ð›½_{0,k}$, $ð›½_{1,k}$, $ð›½_{2,k}$ are the model coefficients for each category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X_train = train_df[['popular', 'genre']]\n",
    "y_train = train_df['category']\n",
    "X_test = test_df[['popular', 'genre']]\n",
    "y_test = test_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.54027342 -5.32328568]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "\n",
    "# fit the model with data\n",
    "res = logreg.fit(X_train, y_train)\n",
    "\n",
    "predProbs = res.predict_proba(X_train)\n",
    "\n",
    "\n",
    "\n",
    "print(logreg.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.253422\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               category   No. Observations:                80000\n",
      "Model:                          Logit   Df Residuals:                    79998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 23 Oct 2024   Pseudo R-squ.:                  0.6342\n",
      "Time:                        10:52:09   Log-Likelihood:                -20274.\n",
      "converged:                       True   LL-Null:                       -55422.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "popular        3.3744      0.034     98.944      0.000       3.308       3.441\n",
      "genre         -5.3555      0.041   -129.146      0.000      -5.437      -5.274\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "log_reg = sm.Logit(y_train, X_train).fit() \n",
    "\n",
    "print(log_reg.summary()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8536, 1232],\n",
       "       [1176, 9056]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = res.predict(X_test)\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$ and false positives is $C_{0,1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      9768\n",
      "           1       0.88      0.89      0.88     10232\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#target_names = ['without diabetes', 'with diabetes']\n",
    "conf_matrix = classification_report(y_test, y_pred)\n",
    "print(conf_matrix)#, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "True Positive Rate (Sensitivity): 0.89\n",
      "False Positive Rate: 0.13\n",
      "Specificity: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate TPR (Sensitivity)\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "# Calculate FPR\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"True Positive Rate (Sensitivity): {tpr:.2f}\")\n",
    "print(f\"False Positive Rate: {fpr:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[8214 1554]\n",
      " [ 924 9308]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      9768\n",
      "           1       0.86      0.91      0.88     10232\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate (Sensitivity): 0.91\n",
      "False Positive Rate: 0.16\n",
      "Specificity: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories on the test data\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate TPR (Sensitivity)\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "# Calculate FPR\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"True Positive Rate (Sensitivity): {tpr:.2f}\")\n",
    "print(f\"False Positive Rate: {fpr:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[8288 1480]\n",
      " [ 999 9233]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      9768\n",
      "           1       0.86      0.90      0.88     10232\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate (Sensitivity): 0.90\n",
      "False Positive Rate: 0.15\n",
      "Specificity: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Fit the QDA model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories on the test data\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate TPR (Sensitivity)\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "# Calculate FPR\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"True Positive Rate (Sensitivity): {tpr:.2f}\")\n",
    "print(f\"False Positive Rate: {fpr:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for K=1:\n",
      "Confusion Matrix:\n",
      " [[8131 1637]\n",
      " [1647 8585]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      9768\n",
      "           1       0.84      0.84      0.84     10232\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate (Sensitivity): 0.84\n",
      "False Positive Rate: 0.17\n",
      "Specificity: 0.83\n",
      "\n",
      "Results for K=5:\n",
      "Confusion Matrix:\n",
      " [[8419 1349]\n",
      " [1339 8893]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      9768\n",
      "           1       0.87      0.87      0.87     10232\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate (Sensitivity): 0.87\n",
      "False Positive Rate: 0.14\n",
      "Specificity: 0.86\n",
      "\n",
      "Results for K=10:\n",
      "Confusion Matrix:\n",
      " [[8654 1114]\n",
      " [1495 8737]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      9768\n",
      "           1       0.89      0.85      0.87     10232\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate (Sensitivity): 0.85\n",
      "False Positive Rate: 0.11\n",
      "Specificity: 0.89\n",
      "\n",
      "Results for K=50:\n",
      "Confusion Matrix:\n",
      " [[8615 1153]\n",
      " [1292 8940]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      9768\n",
      "           1       0.89      0.87      0.88     10232\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate (Sensitivity): 0.87\n",
      "False Positive Rate: 0.12\n",
      "Specificity: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_values = [1, 5, 10, 50]\n",
    "\n",
    "for k in k_values: \n",
    "    # Fit the KNN model \n",
    "    knn = KNeighborsClassifier(n_neighbors=k) \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\nResults for K={k}:\")\n",
    "    # Predict the categories on the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix )\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate TPR (Sensitivity)\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calculate FPR\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Display the metrics\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"True Positive Rate (Sensitivity): {tpr:.2f}\")\n",
    "    print(f\"False Positive Rate: {fpr:.2f}\")\n",
    "    print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[8080 1688]\n",
      " [1086 9146]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      9768\n",
      "           1       0.84      0.89      0.87     10232\n",
      "\n",
      "    accuracy                           0.86     20000\n",
      "   macro avg       0.86      0.86      0.86     20000\n",
      "weighted avg       0.86      0.86      0.86     20000\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate (Sensitivity): 0.89\n",
      "False Positive Rate: 0.17\n",
      "Specificity: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Fit the Gaussian Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the categories on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix )\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate TPR (Sensitivity)\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "# Calculate FPR\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"True Positive Rate (Sensitivity): {tpr:.2f}\")\n",
    "print(f\"False Positive Rate: {fpr:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:\n",
    "\n",
    "Accuracy: 0.88\n",
    "Sensitivity: 0.89\n",
    "Specificity: 0.87\n",
    "Low bias, moderate variance\n",
    "\n",
    "Linear Discriminant Analysis (LDA):\n",
    "\n",
    "Accuracy: 0.88\n",
    "Sensitivity: 0.91\n",
    "Specificity: 0.84\n",
    "Moderate bias, lower variance due to a more rigid decision boundary assumption.\n",
    "\n",
    "Quadratic Discriminant Analysis (QDA):\n",
    "\n",
    "Accuracy: 0.88\n",
    "Sensitivity: 0.90\n",
    "Specificity: 0.85\n",
    "Lower bias, higher variance due to flexible decision boundaries.\n",
    "\n",
    "K-Nearest Neighbors (KNN):\n",
    "\n",
    "K=1: Accuracy: 0.84, Sensitivity: 0.84, Specificity: 0.83 (High variance, low bias)\n",
    "K=5: Accuracy: 0.87, Sensitivity: 0.87, Specificity: 0.86 (Reduced variance, slightly increased bias)\n",
    "K=10: Accuracy: 0.87, Sensitivity: 0.85, Specificity: 0.89 (Good balance of bias-variance)\n",
    "K=50: Accuracy: 0.88, Sensitivity: 0.87, Specificity: 0.88 (Low variance, higher bias)\n",
    "Naive Bayes:\n",
    "\n",
    "Accuracy: 0.86\n",
    "Sensitivity: 0.89\n",
    "Specificity: 0.83\n",
    "High bias, low variance due to independence assumption\n",
    "\n",
    "Logistic Regression, LDA, and KNN with K=50 perform similarly well with Logistic regression being the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
